// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/servables/tensorflow/session_bundle_config.proto

#include "tensorflow_serving/servables/tensorflow/session_bundle_config.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// This is a temporary google only hack
#ifdef GOOGLE_PROTOBUF_ENFORCE_UNIQUENESS
#include "third_party/protobuf/version.h"
#endif
// @@protoc_insertion_point(includes)

namespace protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fconfig_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fconfig_2eproto ::google::protobuf::internal::SCCInfo<7> scc_info_ConfigProto;
}  // namespace protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fconfig_2eproto
namespace protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto ::google::protobuf::internal::SCCInfo<1> scc_info_NamedTensorProto;
}  // namespace protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto
namespace protobuf_google_2fprotobuf_2fwrappers_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_google_2fprotobuf_2fwrappers_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_Int32Value;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_google_2fprotobuf_2fwrappers_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_Int64Value;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_google_2fprotobuf_2fwrappers_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_StringValue;
}  // namespace protobuf_google_2fprotobuf_2fwrappers_2eproto
namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_BatchingParameters;
}  // namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto
namespace tensorflow {
namespace serving {
class SessionBundleConfigDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<SessionBundleConfig>
      _instance;
} _SessionBundleConfig_default_instance_;
class BatchingParametersDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<BatchingParameters>
      _instance;
} _BatchingParameters_default_instance_;
}  // namespace serving
}  // namespace tensorflow
namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto {
static void InitDefaultsSessionBundleConfig() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_SessionBundleConfig_default_instance_;
    new (ptr) ::tensorflow::serving::SessionBundleConfig();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::SessionBundleConfig::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<4> scc_info_SessionBundleConfig =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 4, InitDefaultsSessionBundleConfig}, {
      &protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fconfig_2eproto::scc_info_ConfigProto.base,
      &protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_BatchingParameters.base,
      &protobuf_google_2fprotobuf_2fwrappers_2eproto::scc_info_Int32Value.base,
      &protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto::scc_info_NamedTensorProto.base,}};

static void InitDefaultsBatchingParameters() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_BatchingParameters_default_instance_;
    new (ptr) ::tensorflow::serving::BatchingParameters();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::BatchingParameters::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<2> scc_info_BatchingParameters =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsBatchingParameters}, {
      &protobuf_google_2fprotobuf_2fwrappers_2eproto::scc_info_Int64Value.base,
      &protobuf_google_2fprotobuf_2fwrappers_2eproto::scc_info_StringValue.base,}};

void InitDefaults() {
  ::google::protobuf::internal::InitSCC(&scc_info_SessionBundleConfig.base);
  ::google::protobuf::internal::InitSCC(&scc_info_BatchingParameters.base);
}

::google::protobuf::Metadata file_level_metadata[2];

const ::google::protobuf::uint32 TableStruct::offsets[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, session_target_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, session_config_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, batching_parameters_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, session_run_load_threadpool_index_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, experimental_transient_ram_bytes_during_load_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, saved_model_tags_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, experimental_fixed_input_tensors_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, enable_model_warmup_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, max_batch_size_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, batch_timeout_micros_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, max_enqueued_batches_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, num_batch_threads_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, thread_pool_name_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, allowed_batch_sizes_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, pad_variable_length_inputs_),
};
static const ::google::protobuf::internal::MigrationSchema schemas[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, sizeof(::tensorflow::serving::SessionBundleConfig)},
  { 13, -1, sizeof(::tensorflow::serving::BatchingParameters)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_SessionBundleConfig_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_BatchingParameters_default_instance_),
};

void protobuf_AssignDescriptors() {
  AddDescriptors();
  AssignDescriptors(
      "tensorflow_serving/servables/tensorflow/session_bundle_config.proto", schemas, file_default_instances, TableStruct::offsets,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_PROTOBUF_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 2);
}

void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
      "\nCtensorflow_serving/servables/tensorflo"
      "w/session_bundle_config.proto\022\022tensorflo"
      "w.serving\032\036google/protobuf/wrappers.prot"
      "o\032/diplomacy_tensorflow/core/protobuf/co"
      "nfig.proto\0325diplomacy_tensorflow/core/pr"
      "otobuf/named_tensor.proto\"\266\003\n\023SessionBun"
      "dleConfig\022\026\n\016session_target\030\001 \001(\t\0229\n\016ses"
      "sion_config\030\002 \001(\0132!.diplomacy.tensorflow"
      ".ConfigProto\022C\n\023batching_parameters\030\003 \001("
      "\0132&.tensorflow.serving.BatchingParameter"
      "s\022F\n!session_run_load_threadpool_index\030\004"
      " \001(\0132\033.google.protobuf.Int32Value\0224\n,exp"
      "erimental_transient_ram_bytes_during_loa"
      "d\030\005 \001(\004\022\030\n\020saved_model_tags\030\006 \003(\t\022Q\n exp"
      "erimental_fixed_input_tensors\030\212\006 \003(\0132&.d"
      "iplomacy.tensorflow.NamedTensorProto\022\034\n\023"
      "enable_model_warmup\030\213\006 \001(\010\"\360\002\n\022BatchingP"
      "arameters\0223\n\016max_batch_size\030\001 \001(\0132\033.goog"
      "le.protobuf.Int64Value\0229\n\024batch_timeout_"
      "micros\030\002 \001(\0132\033.google.protobuf.Int64Valu"
      "e\0229\n\024max_enqueued_batches\030\003 \001(\0132\033.google"
      ".protobuf.Int64Value\0226\n\021num_batch_thread"
      "s\030\004 \001(\0132\033.google.protobuf.Int64Value\0226\n\020"
      "thread_pool_name\030\005 \001(\0132\034.google.protobuf"
      ".StringValue\022\033\n\023allowed_batch_sizes\030\006 \003("
      "\003\022\"\n\032pad_variable_length_inputs\030\007 \001(\010b\006p"
      "roto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 1045);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/servables/tensorflow/session_bundle_config.proto", &protobuf_RegisterTypes);
  ::protobuf_google_2fprotobuf_2fwrappers_2eproto::AddDescriptors();
  ::protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fconfig_2eproto::AddDescriptors();
  ::protobuf_diplomacy_5ftensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto::AddDescriptors();
}

void AddDescriptors() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at dynamic initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;
}  // namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto
namespace tensorflow {
namespace serving {

// ===================================================================

void SessionBundleConfig::InitAsDefaultInstance() {
  ::tensorflow::serving::_SessionBundleConfig_default_instance_._instance.get_mutable()->session_config_ = const_cast< ::diplomacy::tensorflow::ConfigProto*>(
      ::diplomacy::tensorflow::ConfigProto::internal_default_instance());
  ::tensorflow::serving::_SessionBundleConfig_default_instance_._instance.get_mutable()->batching_parameters_ = const_cast< ::tensorflow::serving::BatchingParameters*>(
      ::tensorflow::serving::BatchingParameters::internal_default_instance());
  ::tensorflow::serving::_SessionBundleConfig_default_instance_._instance.get_mutable()->session_run_load_threadpool_index_ = const_cast< ::google::protobuf::Int32Value*>(
      ::google::protobuf::Int32Value::internal_default_instance());
}
void SessionBundleConfig::clear_session_config() {
  if (GetArenaNoVirtual() == NULL && session_config_ != NULL) {
    delete session_config_;
  }
  session_config_ = NULL;
}
void SessionBundleConfig::clear_session_run_load_threadpool_index() {
  if (GetArenaNoVirtual() == NULL && session_run_load_threadpool_index_ != NULL) {
    delete session_run_load_threadpool_index_;
  }
  session_run_load_threadpool_index_ = NULL;
}
void SessionBundleConfig::clear_experimental_fixed_input_tensors() {
  experimental_fixed_input_tensors_.Clear();
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SessionBundleConfig::kSessionTargetFieldNumber;
const int SessionBundleConfig::kSessionConfigFieldNumber;
const int SessionBundleConfig::kBatchingParametersFieldNumber;
const int SessionBundleConfig::kSessionRunLoadThreadpoolIndexFieldNumber;
const int SessionBundleConfig::kExperimentalTransientRamBytesDuringLoadFieldNumber;
const int SessionBundleConfig::kSavedModelTagsFieldNumber;
const int SessionBundleConfig::kExperimentalFixedInputTensorsFieldNumber;
const int SessionBundleConfig::kEnableModelWarmupFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SessionBundleConfig::SessionBundleConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_SessionBundleConfig.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.SessionBundleConfig)
}
SessionBundleConfig::SessionBundleConfig(const SessionBundleConfig& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      saved_model_tags_(from.saved_model_tags_),
      experimental_fixed_input_tensors_(from.experimental_fixed_input_tensors_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  session_target_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.session_target().size() > 0) {
    session_target_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_target_);
  }
  if (from.has_session_config()) {
    session_config_ = new ::diplomacy::tensorflow::ConfigProto(*from.session_config_);
  } else {
    session_config_ = NULL;
  }
  if (from.has_batching_parameters()) {
    batching_parameters_ = new ::tensorflow::serving::BatchingParameters(*from.batching_parameters_);
  } else {
    batching_parameters_ = NULL;
  }
  if (from.has_session_run_load_threadpool_index()) {
    session_run_load_threadpool_index_ = new ::google::protobuf::Int32Value(*from.session_run_load_threadpool_index_);
  } else {
    session_run_load_threadpool_index_ = NULL;
  }
  ::memcpy(&experimental_transient_ram_bytes_during_load_, &from.experimental_transient_ram_bytes_during_load_,
    static_cast<size_t>(reinterpret_cast<char*>(&enable_model_warmup_) -
    reinterpret_cast<char*>(&experimental_transient_ram_bytes_during_load_)) + sizeof(enable_model_warmup_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.SessionBundleConfig)
}

void SessionBundleConfig::SharedCtor() {
  session_target_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(&session_config_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&enable_model_warmup_) -
      reinterpret_cast<char*>(&session_config_)) + sizeof(enable_model_warmup_));
}

SessionBundleConfig::~SessionBundleConfig() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.SessionBundleConfig)
  SharedDtor();
}

void SessionBundleConfig::SharedDtor() {
  session_target_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) delete session_config_;
  if (this != internal_default_instance()) delete batching_parameters_;
  if (this != internal_default_instance()) delete session_run_load_threadpool_index_;
}

void SessionBundleConfig::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* SessionBundleConfig::descriptor() {
  ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const SessionBundleConfig& SessionBundleConfig::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_SessionBundleConfig.base);
  return *internal_default_instance();
}


void SessionBundleConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.SessionBundleConfig)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  saved_model_tags_.Clear();
  experimental_fixed_input_tensors_.Clear();
  session_target_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (GetArenaNoVirtual() == NULL && session_config_ != NULL) {
    delete session_config_;
  }
  session_config_ = NULL;
  if (GetArenaNoVirtual() == NULL && batching_parameters_ != NULL) {
    delete batching_parameters_;
  }
  batching_parameters_ = NULL;
  if (GetArenaNoVirtual() == NULL && session_run_load_threadpool_index_ != NULL) {
    delete session_run_load_threadpool_index_;
  }
  session_run_load_threadpool_index_ = NULL;
  ::memset(&experimental_transient_ram_bytes_during_load_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&enable_model_warmup_) -
      reinterpret_cast<char*>(&experimental_transient_ram_bytes_during_load_)) + sizeof(enable_model_warmup_));
  _internal_metadata_.Clear();
}

bool SessionBundleConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.SessionBundleConfig)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(16383u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // string session_target = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_session_target()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->session_target().data(), static_cast<int>(this->session_target().length()),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.SessionBundleConfig.session_target"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .diplomacy.tensorflow.ConfigProto session_config = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_session_config()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.BatchingParameters batching_parameters = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(26u /* 26 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_batching_parameters()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
      case 4: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(34u /* 34 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_session_run_load_threadpool_index()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // uint64 experimental_transient_ram_bytes_during_load = 5;
      case 5: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(40u /* 40 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &experimental_transient_ram_bytes_during_load_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated string saved_model_tags = 6;
      case 6: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(50u /* 50 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_saved_model_tags()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->saved_model_tags(this->saved_model_tags_size() - 1).data(),
            static_cast<int>(this->saved_model_tags(this->saved_model_tags_size() - 1).length()),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.SessionBundleConfig.saved_model_tags"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated .diplomacy.tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
      case 778: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(82u /* 6226 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
                input, add_experimental_fixed_input_tensors()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool enable_model_warmup = 779;
      case 779: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(88u /* 6232 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &enable_model_warmup_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.SessionBundleConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.SessionBundleConfig)
  return false;
#undef DO_
}

void SessionBundleConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.SessionBundleConfig)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // string session_target = 1;
  if (this->session_target().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_target().data(), static_cast<int>(this->session_target().length()),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.session_target");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->session_target(), output);
  }

  // .diplomacy.tensorflow.ConfigProto session_config = 2;
  if (this->has_session_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_session_config(), output);
  }

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  if (this->has_batching_parameters()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, this->_internal_batching_parameters(), output);
  }

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  if (this->has_session_run_load_threadpool_index()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, this->_internal_session_run_load_threadpool_index(), output);
  }

  // uint64 experimental_transient_ram_bytes_during_load = 5;
  if (this->experimental_transient_ram_bytes_during_load() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(5, this->experimental_transient_ram_bytes_during_load(), output);
  }

  // repeated string saved_model_tags = 6;
  for (int i = 0, n = this->saved_model_tags_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->saved_model_tags(i).data(), static_cast<int>(this->saved_model_tags(i).length()),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.saved_model_tags");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      6, this->saved_model_tags(i), output);
  }

  // repeated .diplomacy.tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->experimental_fixed_input_tensors_size()); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      778,
      this->experimental_fixed_input_tensors(static_cast<int>(i)),
      output);
  }

  // bool enable_model_warmup = 779;
  if (this->enable_model_warmup() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(779, this->enable_model_warmup(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.SessionBundleConfig)
}

::google::protobuf::uint8* SessionBundleConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.SessionBundleConfig)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // string session_target = 1;
  if (this->session_target().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_target().data(), static_cast<int>(this->session_target().length()),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.session_target");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->session_target(), target);
  }

  // .diplomacy.tensorflow.ConfigProto session_config = 2;
  if (this->has_session_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_session_config(), deterministic, target);
  }

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  if (this->has_batching_parameters()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        3, this->_internal_batching_parameters(), deterministic, target);
  }

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  if (this->has_session_run_load_threadpool_index()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        4, this->_internal_session_run_load_threadpool_index(), deterministic, target);
  }

  // uint64 experimental_transient_ram_bytes_during_load = 5;
  if (this->experimental_transient_ram_bytes_during_load() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(5, this->experimental_transient_ram_bytes_during_load(), target);
  }

  // repeated string saved_model_tags = 6;
  for (int i = 0, n = this->saved_model_tags_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->saved_model_tags(i).data(), static_cast<int>(this->saved_model_tags(i).length()),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.saved_model_tags");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(6, this->saved_model_tags(i), target);
  }

  // repeated .diplomacy.tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->experimental_fixed_input_tensors_size()); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        778, this->experimental_fixed_input_tensors(static_cast<int>(i)), deterministic, target);
  }

  // bool enable_model_warmup = 779;
  if (this->enable_model_warmup() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(779, this->enable_model_warmup(), target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.SessionBundleConfig)
  return target;
}

size_t SessionBundleConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.SessionBundleConfig)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // repeated string saved_model_tags = 6;
  total_size += 1 *
      ::google::protobuf::internal::FromIntSize(this->saved_model_tags_size());
  for (int i = 0, n = this->saved_model_tags_size(); i < n; i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->saved_model_tags(i));
  }

  // repeated .diplomacy.tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  {
    unsigned int count = static_cast<unsigned int>(this->experimental_fixed_input_tensors_size());
    total_size += 2UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSize(
          this->experimental_fixed_input_tensors(static_cast<int>(i)));
    }
  }

  // string session_target = 1;
  if (this->session_target().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->session_target());
  }

  // .diplomacy.tensorflow.ConfigProto session_config = 2;
  if (this->has_session_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *session_config_);
  }

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  if (this->has_batching_parameters()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *batching_parameters_);
  }

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  if (this->has_session_run_load_threadpool_index()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *session_run_load_threadpool_index_);
  }

  // uint64 experimental_transient_ram_bytes_during_load = 5;
  if (this->experimental_transient_ram_bytes_during_load() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->experimental_transient_ram_bytes_during_load());
  }

  // bool enable_model_warmup = 779;
  if (this->enable_model_warmup() != 0) {
    total_size += 2 + 1;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void SessionBundleConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.SessionBundleConfig)
  GOOGLE_DCHECK_NE(&from, this);
  const SessionBundleConfig* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const SessionBundleConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.SessionBundleConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.SessionBundleConfig)
    MergeFrom(*source);
  }
}

void SessionBundleConfig::MergeFrom(const SessionBundleConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.SessionBundleConfig)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  saved_model_tags_.MergeFrom(from.saved_model_tags_);
  experimental_fixed_input_tensors_.MergeFrom(from.experimental_fixed_input_tensors_);
  if (from.session_target().size() > 0) {

    session_target_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_target_);
  }
  if (from.has_session_config()) {
    mutable_session_config()->::diplomacy::tensorflow::ConfigProto::MergeFrom(from.session_config());
  }
  if (from.has_batching_parameters()) {
    mutable_batching_parameters()->::tensorflow::serving::BatchingParameters::MergeFrom(from.batching_parameters());
  }
  if (from.has_session_run_load_threadpool_index()) {
    mutable_session_run_load_threadpool_index()->::google::protobuf::Int32Value::MergeFrom(from.session_run_load_threadpool_index());
  }
  if (from.experimental_transient_ram_bytes_during_load() != 0) {
    set_experimental_transient_ram_bytes_during_load(from.experimental_transient_ram_bytes_during_load());
  }
  if (from.enable_model_warmup() != 0) {
    set_enable_model_warmup(from.enable_model_warmup());
  }
}

void SessionBundleConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.SessionBundleConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SessionBundleConfig::CopyFrom(const SessionBundleConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.SessionBundleConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SessionBundleConfig::IsInitialized() const {
  return true;
}

void SessionBundleConfig::Swap(SessionBundleConfig* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SessionBundleConfig::InternalSwap(SessionBundleConfig* other) {
  using std::swap;
  saved_model_tags_.InternalSwap(CastToBase(&other->saved_model_tags_));
  CastToBase(&experimental_fixed_input_tensors_)->InternalSwap(CastToBase(&other->experimental_fixed_input_tensors_));
  session_target_.Swap(&other->session_target_, &::google::protobuf::internal::GetEmptyStringAlreadyInited(),
    GetArenaNoVirtual());
  swap(session_config_, other->session_config_);
  swap(batching_parameters_, other->batching_parameters_);
  swap(session_run_load_threadpool_index_, other->session_run_load_threadpool_index_);
  swap(experimental_transient_ram_bytes_during_load_, other->experimental_transient_ram_bytes_during_load_);
  swap(enable_model_warmup_, other->enable_model_warmup_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata SessionBundleConfig::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void BatchingParameters::InitAsDefaultInstance() {
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->max_batch_size_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->batch_timeout_micros_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->max_enqueued_batches_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->num_batch_threads_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->thread_pool_name_ = const_cast< ::google::protobuf::StringValue*>(
      ::google::protobuf::StringValue::internal_default_instance());
}
void BatchingParameters::clear_max_batch_size() {
  if (GetArenaNoVirtual() == NULL && max_batch_size_ != NULL) {
    delete max_batch_size_;
  }
  max_batch_size_ = NULL;
}
void BatchingParameters::clear_batch_timeout_micros() {
  if (GetArenaNoVirtual() == NULL && batch_timeout_micros_ != NULL) {
    delete batch_timeout_micros_;
  }
  batch_timeout_micros_ = NULL;
}
void BatchingParameters::clear_max_enqueued_batches() {
  if (GetArenaNoVirtual() == NULL && max_enqueued_batches_ != NULL) {
    delete max_enqueued_batches_;
  }
  max_enqueued_batches_ = NULL;
}
void BatchingParameters::clear_num_batch_threads() {
  if (GetArenaNoVirtual() == NULL && num_batch_threads_ != NULL) {
    delete num_batch_threads_;
  }
  num_batch_threads_ = NULL;
}
void BatchingParameters::clear_thread_pool_name() {
  if (GetArenaNoVirtual() == NULL && thread_pool_name_ != NULL) {
    delete thread_pool_name_;
  }
  thread_pool_name_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int BatchingParameters::kMaxBatchSizeFieldNumber;
const int BatchingParameters::kBatchTimeoutMicrosFieldNumber;
const int BatchingParameters::kMaxEnqueuedBatchesFieldNumber;
const int BatchingParameters::kNumBatchThreadsFieldNumber;
const int BatchingParameters::kThreadPoolNameFieldNumber;
const int BatchingParameters::kAllowedBatchSizesFieldNumber;
const int BatchingParameters::kPadVariableLengthInputsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

BatchingParameters::BatchingParameters()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_BatchingParameters.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.BatchingParameters)
}
BatchingParameters::BatchingParameters(const BatchingParameters& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      allowed_batch_sizes_(from.allowed_batch_sizes_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_max_batch_size()) {
    max_batch_size_ = new ::google::protobuf::Int64Value(*from.max_batch_size_);
  } else {
    max_batch_size_ = NULL;
  }
  if (from.has_batch_timeout_micros()) {
    batch_timeout_micros_ = new ::google::protobuf::Int64Value(*from.batch_timeout_micros_);
  } else {
    batch_timeout_micros_ = NULL;
  }
  if (from.has_max_enqueued_batches()) {
    max_enqueued_batches_ = new ::google::protobuf::Int64Value(*from.max_enqueued_batches_);
  } else {
    max_enqueued_batches_ = NULL;
  }
  if (from.has_num_batch_threads()) {
    num_batch_threads_ = new ::google::protobuf::Int64Value(*from.num_batch_threads_);
  } else {
    num_batch_threads_ = NULL;
  }
  if (from.has_thread_pool_name()) {
    thread_pool_name_ = new ::google::protobuf::StringValue(*from.thread_pool_name_);
  } else {
    thread_pool_name_ = NULL;
  }
  pad_variable_length_inputs_ = from.pad_variable_length_inputs_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.BatchingParameters)
}

void BatchingParameters::SharedCtor() {
  ::memset(&max_batch_size_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&pad_variable_length_inputs_) -
      reinterpret_cast<char*>(&max_batch_size_)) + sizeof(pad_variable_length_inputs_));
}

BatchingParameters::~BatchingParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.BatchingParameters)
  SharedDtor();
}

void BatchingParameters::SharedDtor() {
  if (this != internal_default_instance()) delete max_batch_size_;
  if (this != internal_default_instance()) delete batch_timeout_micros_;
  if (this != internal_default_instance()) delete max_enqueued_batches_;
  if (this != internal_default_instance()) delete num_batch_threads_;
  if (this != internal_default_instance()) delete thread_pool_name_;
}

void BatchingParameters::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* BatchingParameters::descriptor() {
  ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const BatchingParameters& BatchingParameters::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_BatchingParameters.base);
  return *internal_default_instance();
}


void BatchingParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.BatchingParameters)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  allowed_batch_sizes_.Clear();
  if (GetArenaNoVirtual() == NULL && max_batch_size_ != NULL) {
    delete max_batch_size_;
  }
  max_batch_size_ = NULL;
  if (GetArenaNoVirtual() == NULL && batch_timeout_micros_ != NULL) {
    delete batch_timeout_micros_;
  }
  batch_timeout_micros_ = NULL;
  if (GetArenaNoVirtual() == NULL && max_enqueued_batches_ != NULL) {
    delete max_enqueued_batches_;
  }
  max_enqueued_batches_ = NULL;
  if (GetArenaNoVirtual() == NULL && num_batch_threads_ != NULL) {
    delete num_batch_threads_;
  }
  num_batch_threads_ = NULL;
  if (GetArenaNoVirtual() == NULL && thread_pool_name_ != NULL) {
    delete thread_pool_name_;
  }
  thread_pool_name_ = NULL;
  pad_variable_length_inputs_ = false;
  _internal_metadata_.Clear();
}

bool BatchingParameters::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.BatchingParameters)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.protobuf.Int64Value max_batch_size = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_max_batch_size()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value batch_timeout_micros = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_batch_timeout_micros()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value max_enqueued_batches = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(26u /* 26 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_max_enqueued_batches()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value num_batch_threads = 4;
      case 4: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(34u /* 34 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_num_batch_threads()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.StringValue thread_pool_name = 5;
      case 5: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(42u /* 42 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_thread_pool_name()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated int64 allowed_batch_sizes = 6;
      case 6: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(50u /* 50 & 0xFF */)) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, this->mutable_allowed_batch_sizes())));
        } else if (
            static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(48u /* 48 & 0xFF */)) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 1, 50u, input, this->mutable_allowed_batch_sizes())));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool pad_variable_length_inputs = 7;
      case 7: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(56u /* 56 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &pad_variable_length_inputs_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.BatchingParameters)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.BatchingParameters)
  return false;
#undef DO_
}

void BatchingParameters::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.BatchingParameters)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .google.protobuf.Int64Value max_batch_size = 1;
  if (this->has_max_batch_size()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_max_batch_size(), output);
  }

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  if (this->has_batch_timeout_micros()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_batch_timeout_micros(), output);
  }

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  if (this->has_max_enqueued_batches()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, this->_internal_max_enqueued_batches(), output);
  }

  // .google.protobuf.Int64Value num_batch_threads = 4;
  if (this->has_num_batch_threads()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, this->_internal_num_batch_threads(), output);
  }

  // .google.protobuf.StringValue thread_pool_name = 5;
  if (this->has_thread_pool_name()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      5, this->_internal_thread_pool_name(), output);
  }

  // repeated int64 allowed_batch_sizes = 6;
  if (this->allowed_batch_sizes_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(6, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(static_cast< ::google::protobuf::uint32>(
        _allowed_batch_sizes_cached_byte_size_));
  }
  for (int i = 0, n = this->allowed_batch_sizes_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64NoTag(
      this->allowed_batch_sizes(i), output);
  }

  // bool pad_variable_length_inputs = 7;
  if (this->pad_variable_length_inputs() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(7, this->pad_variable_length_inputs(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.BatchingParameters)
}

::google::protobuf::uint8* BatchingParameters::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.BatchingParameters)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .google.protobuf.Int64Value max_batch_size = 1;
  if (this->has_max_batch_size()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_max_batch_size(), deterministic, target);
  }

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  if (this->has_batch_timeout_micros()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_batch_timeout_micros(), deterministic, target);
  }

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  if (this->has_max_enqueued_batches()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        3, this->_internal_max_enqueued_batches(), deterministic, target);
  }

  // .google.protobuf.Int64Value num_batch_threads = 4;
  if (this->has_num_batch_threads()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        4, this->_internal_num_batch_threads(), deterministic, target);
  }

  // .google.protobuf.StringValue thread_pool_name = 5;
  if (this->has_thread_pool_name()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        5, this->_internal_thread_pool_name(), deterministic, target);
  }

  // repeated int64 allowed_batch_sizes = 6;
  if (this->allowed_batch_sizes_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      6,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
        static_cast< ::google::protobuf::int32>(
            _allowed_batch_sizes_cached_byte_size_), target);
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt64NoTagToArray(this->allowed_batch_sizes_, target);
  }

  // bool pad_variable_length_inputs = 7;
  if (this->pad_variable_length_inputs() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(7, this->pad_variable_length_inputs(), target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.BatchingParameters)
  return target;
}

size_t BatchingParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.BatchingParameters)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // repeated int64 allowed_batch_sizes = 6;
  {
    size_t data_size = ::google::protobuf::internal::WireFormatLite::
      Int64Size(this->allowed_batch_sizes_);
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
            static_cast< ::google::protobuf::int32>(data_size));
    }
    int cached_size = ::google::protobuf::internal::ToCachedSize(data_size);
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _allowed_batch_sizes_cached_byte_size_ = cached_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  // .google.protobuf.Int64Value max_batch_size = 1;
  if (this->has_max_batch_size()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *max_batch_size_);
  }

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  if (this->has_batch_timeout_micros()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *batch_timeout_micros_);
  }

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  if (this->has_max_enqueued_batches()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *max_enqueued_batches_);
  }

  // .google.protobuf.Int64Value num_batch_threads = 4;
  if (this->has_num_batch_threads()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *num_batch_threads_);
  }

  // .google.protobuf.StringValue thread_pool_name = 5;
  if (this->has_thread_pool_name()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *thread_pool_name_);
  }

  // bool pad_variable_length_inputs = 7;
  if (this->pad_variable_length_inputs() != 0) {
    total_size += 1 + 1;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void BatchingParameters::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.BatchingParameters)
  GOOGLE_DCHECK_NE(&from, this);
  const BatchingParameters* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const BatchingParameters>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.BatchingParameters)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.BatchingParameters)
    MergeFrom(*source);
  }
}

void BatchingParameters::MergeFrom(const BatchingParameters& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.BatchingParameters)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  allowed_batch_sizes_.MergeFrom(from.allowed_batch_sizes_);
  if (from.has_max_batch_size()) {
    mutable_max_batch_size()->::google::protobuf::Int64Value::MergeFrom(from.max_batch_size());
  }
  if (from.has_batch_timeout_micros()) {
    mutable_batch_timeout_micros()->::google::protobuf::Int64Value::MergeFrom(from.batch_timeout_micros());
  }
  if (from.has_max_enqueued_batches()) {
    mutable_max_enqueued_batches()->::google::protobuf::Int64Value::MergeFrom(from.max_enqueued_batches());
  }
  if (from.has_num_batch_threads()) {
    mutable_num_batch_threads()->::google::protobuf::Int64Value::MergeFrom(from.num_batch_threads());
  }
  if (from.has_thread_pool_name()) {
    mutable_thread_pool_name()->::google::protobuf::StringValue::MergeFrom(from.thread_pool_name());
  }
  if (from.pad_variable_length_inputs() != 0) {
    set_pad_variable_length_inputs(from.pad_variable_length_inputs());
  }
}

void BatchingParameters::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.BatchingParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void BatchingParameters::CopyFrom(const BatchingParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.BatchingParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool BatchingParameters::IsInitialized() const {
  return true;
}

void BatchingParameters::Swap(BatchingParameters* other) {
  if (other == this) return;
  InternalSwap(other);
}
void BatchingParameters::InternalSwap(BatchingParameters* other) {
  using std::swap;
  allowed_batch_sizes_.InternalSwap(&other->allowed_batch_sizes_);
  swap(max_batch_size_, other->max_batch_size_);
  swap(batch_timeout_micros_, other->batch_timeout_micros_);
  swap(max_enqueued_batches_, other->max_enqueued_batches_);
  swap(num_batch_threads_, other->num_batch_threads_);
  swap(thread_pool_name_, other->thread_pool_name_);
  swap(pad_variable_length_inputs_, other->pad_variable_length_inputs_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata BatchingParameters::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages];
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
namespace google {
namespace protobuf {
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::SessionBundleConfig* Arena::CreateMaybeMessage< ::tensorflow::serving::SessionBundleConfig >(Arena* arena) {
  return Arena::CreateInternal< ::tensorflow::serving::SessionBundleConfig >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::BatchingParameters* Arena::CreateMaybeMessage< ::tensorflow::serving::BatchingParameters >(Arena* arena) {
  return Arena::CreateInternal< ::tensorflow::serving::BatchingParameters >(arena);
}
}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)
