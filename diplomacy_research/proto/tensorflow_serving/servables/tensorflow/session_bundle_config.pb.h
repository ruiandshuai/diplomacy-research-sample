// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/servables/tensorflow/session_bundle_config.proto

#ifndef PROTOBUF_INCLUDED_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto
#define PROTOBUF_INCLUDED_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 3006001
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/inlined_string_field.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/unknown_field_set.h>
#include <google/protobuf/wrappers.pb.h>
#include "diplomacy_tensorflow/core/protobuf/config.pb.h"
#include "diplomacy_tensorflow/core/protobuf/named_tensor.pb.h"
// @@protoc_insertion_point(includes)
#define PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto 

namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto {
// Internal implementation detail -- do not use these members.
struct TableStruct {
  static const ::google::protobuf::internal::ParseTableField entries[];
  static const ::google::protobuf::internal::AuxillaryParseTableField aux[];
  static const ::google::protobuf::internal::ParseTable schema[2];
  static const ::google::protobuf::internal::FieldMetadata field_metadata[];
  static const ::google::protobuf::internal::SerializationTable serialization_table[];
  static const ::google::protobuf::uint32 offsets[];
};
void AddDescriptors();
}  // namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto
namespace tensorflow {
namespace serving {
class BatchingParameters;
class BatchingParametersDefaultTypeInternal;
extern BatchingParametersDefaultTypeInternal _BatchingParameters_default_instance_;
class SessionBundleConfig;
class SessionBundleConfigDefaultTypeInternal;
extern SessionBundleConfigDefaultTypeInternal _SessionBundleConfig_default_instance_;
}  // namespace serving
}  // namespace tensorflow
namespace google {
namespace protobuf {
template<> ::tensorflow::serving::BatchingParameters* Arena::CreateMaybeMessage<::tensorflow::serving::BatchingParameters>(Arena*);
template<> ::tensorflow::serving::SessionBundleConfig* Arena::CreateMaybeMessage<::tensorflow::serving::SessionBundleConfig>(Arena*);
}  // namespace protobuf
}  // namespace google
namespace tensorflow {
namespace serving {

// ===================================================================

class SessionBundleConfig : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.SessionBundleConfig) */ {
 public:
  SessionBundleConfig();
  virtual ~SessionBundleConfig();

  SessionBundleConfig(const SessionBundleConfig& from);

  inline SessionBundleConfig& operator=(const SessionBundleConfig& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SessionBundleConfig(SessionBundleConfig&& from) noexcept
    : SessionBundleConfig() {
    *this = ::std::move(from);
  }

  inline SessionBundleConfig& operator=(SessionBundleConfig&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const SessionBundleConfig& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SessionBundleConfig* internal_default_instance() {
    return reinterpret_cast<const SessionBundleConfig*>(
               &_SessionBundleConfig_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  void Swap(SessionBundleConfig* other);
  friend void swap(SessionBundleConfig& a, SessionBundleConfig& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SessionBundleConfig* New() const final {
    return CreateMaybeMessage<SessionBundleConfig>(NULL);
  }

  SessionBundleConfig* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SessionBundleConfig>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SessionBundleConfig& from);
  void MergeFrom(const SessionBundleConfig& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SessionBundleConfig* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated string saved_model_tags = 6;
  int saved_model_tags_size() const;
  void clear_saved_model_tags();
  static const int kSavedModelTagsFieldNumber = 6;
  const ::std::string& saved_model_tags(int index) const;
  ::std::string* mutable_saved_model_tags(int index);
  void set_saved_model_tags(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_saved_model_tags(int index, ::std::string&& value);
  #endif
  void set_saved_model_tags(int index, const char* value);
  void set_saved_model_tags(int index, const char* value, size_t size);
  ::std::string* add_saved_model_tags();
  void add_saved_model_tags(const ::std::string& value);
  #if LANG_CXX11
  void add_saved_model_tags(::std::string&& value);
  #endif
  void add_saved_model_tags(const char* value);
  void add_saved_model_tags(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& saved_model_tags() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_saved_model_tags();

  // repeated .diplomacy.tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  int experimental_fixed_input_tensors_size() const;
  void clear_experimental_fixed_input_tensors();
  static const int kExperimentalFixedInputTensorsFieldNumber = 778;
  ::diplomacy::tensorflow::NamedTensorProto* mutable_experimental_fixed_input_tensors(int index);
  ::google::protobuf::RepeatedPtrField< ::diplomacy::tensorflow::NamedTensorProto >*
      mutable_experimental_fixed_input_tensors();
  const ::diplomacy::tensorflow::NamedTensorProto& experimental_fixed_input_tensors(int index) const;
  ::diplomacy::tensorflow::NamedTensorProto* add_experimental_fixed_input_tensors();
  const ::google::protobuf::RepeatedPtrField< ::diplomacy::tensorflow::NamedTensorProto >&
      experimental_fixed_input_tensors() const;

  // string session_target = 1;
  void clear_session_target();
  static const int kSessionTargetFieldNumber = 1;
  const ::std::string& session_target() const;
  void set_session_target(const ::std::string& value);
  #if LANG_CXX11
  void set_session_target(::std::string&& value);
  #endif
  void set_session_target(const char* value);
  void set_session_target(const char* value, size_t size);
  ::std::string* mutable_session_target();
  ::std::string* release_session_target();
  void set_allocated_session_target(::std::string* session_target);

  // .diplomacy.tensorflow.ConfigProto session_config = 2;
  bool has_session_config() const;
  void clear_session_config();
  static const int kSessionConfigFieldNumber = 2;
  private:
  const ::diplomacy::tensorflow::ConfigProto& _internal_session_config() const;
  public:
  const ::diplomacy::tensorflow::ConfigProto& session_config() const;
  ::diplomacy::tensorflow::ConfigProto* release_session_config();
  ::diplomacy::tensorflow::ConfigProto* mutable_session_config();
  void set_allocated_session_config(::diplomacy::tensorflow::ConfigProto* session_config);

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  bool has_batching_parameters() const;
  void clear_batching_parameters();
  static const int kBatchingParametersFieldNumber = 3;
  private:
  const ::tensorflow::serving::BatchingParameters& _internal_batching_parameters() const;
  public:
  const ::tensorflow::serving::BatchingParameters& batching_parameters() const;
  ::tensorflow::serving::BatchingParameters* release_batching_parameters();
  ::tensorflow::serving::BatchingParameters* mutable_batching_parameters();
  void set_allocated_batching_parameters(::tensorflow::serving::BatchingParameters* batching_parameters);

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  bool has_session_run_load_threadpool_index() const;
  void clear_session_run_load_threadpool_index();
  static const int kSessionRunLoadThreadpoolIndexFieldNumber = 4;
  private:
  const ::google::protobuf::Int32Value& _internal_session_run_load_threadpool_index() const;
  public:
  const ::google::protobuf::Int32Value& session_run_load_threadpool_index() const;
  ::google::protobuf::Int32Value* release_session_run_load_threadpool_index();
  ::google::protobuf::Int32Value* mutable_session_run_load_threadpool_index();
  void set_allocated_session_run_load_threadpool_index(::google::protobuf::Int32Value* session_run_load_threadpool_index);

  // uint64 experimental_transient_ram_bytes_during_load = 5;
  void clear_experimental_transient_ram_bytes_during_load();
  static const int kExperimentalTransientRamBytesDuringLoadFieldNumber = 5;
  ::google::protobuf::uint64 experimental_transient_ram_bytes_during_load() const;
  void set_experimental_transient_ram_bytes_during_load(::google::protobuf::uint64 value);

  // bool enable_model_warmup = 779;
  void clear_enable_model_warmup();
  static const int kEnableModelWarmupFieldNumber = 779;
  bool enable_model_warmup() const;
  void set_enable_model_warmup(bool value);

  // @@protoc_insertion_point(class_scope:tensorflow.serving.SessionBundleConfig)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::std::string> saved_model_tags_;
  ::google::protobuf::RepeatedPtrField< ::diplomacy::tensorflow::NamedTensorProto > experimental_fixed_input_tensors_;
  ::google::protobuf::internal::ArenaStringPtr session_target_;
  ::diplomacy::tensorflow::ConfigProto* session_config_;
  ::tensorflow::serving::BatchingParameters* batching_parameters_;
  ::google::protobuf::Int32Value* session_run_load_threadpool_index_;
  ::google::protobuf::uint64 experimental_transient_ram_bytes_during_load_;
  bool enable_model_warmup_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BatchingParameters : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.BatchingParameters) */ {
 public:
  BatchingParameters();
  virtual ~BatchingParameters();

  BatchingParameters(const BatchingParameters& from);

  inline BatchingParameters& operator=(const BatchingParameters& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BatchingParameters(BatchingParameters&& from) noexcept
    : BatchingParameters() {
    *this = ::std::move(from);
  }

  inline BatchingParameters& operator=(BatchingParameters&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor();
  static const BatchingParameters& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BatchingParameters* internal_default_instance() {
    return reinterpret_cast<const BatchingParameters*>(
               &_BatchingParameters_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  void Swap(BatchingParameters* other);
  friend void swap(BatchingParameters& a, BatchingParameters& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BatchingParameters* New() const final {
    return CreateMaybeMessage<BatchingParameters>(NULL);
  }

  BatchingParameters* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BatchingParameters>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BatchingParameters& from);
  void MergeFrom(const BatchingParameters& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BatchingParameters* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated int64 allowed_batch_sizes = 6;
  int allowed_batch_sizes_size() const;
  void clear_allowed_batch_sizes();
  static const int kAllowedBatchSizesFieldNumber = 6;
  ::google::protobuf::int64 allowed_batch_sizes(int index) const;
  void set_allowed_batch_sizes(int index, ::google::protobuf::int64 value);
  void add_allowed_batch_sizes(::google::protobuf::int64 value);
  const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
      allowed_batch_sizes() const;
  ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
      mutable_allowed_batch_sizes();

  // .google.protobuf.Int64Value max_batch_size = 1;
  bool has_max_batch_size() const;
  void clear_max_batch_size();
  static const int kMaxBatchSizeFieldNumber = 1;
  private:
  const ::google::protobuf::Int64Value& _internal_max_batch_size() const;
  public:
  const ::google::protobuf::Int64Value& max_batch_size() const;
  ::google::protobuf::Int64Value* release_max_batch_size();
  ::google::protobuf::Int64Value* mutable_max_batch_size();
  void set_allocated_max_batch_size(::google::protobuf::Int64Value* max_batch_size);

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  bool has_batch_timeout_micros() const;
  void clear_batch_timeout_micros();
  static const int kBatchTimeoutMicrosFieldNumber = 2;
  private:
  const ::google::protobuf::Int64Value& _internal_batch_timeout_micros() const;
  public:
  const ::google::protobuf::Int64Value& batch_timeout_micros() const;
  ::google::protobuf::Int64Value* release_batch_timeout_micros();
  ::google::protobuf::Int64Value* mutable_batch_timeout_micros();
  void set_allocated_batch_timeout_micros(::google::protobuf::Int64Value* batch_timeout_micros);

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  bool has_max_enqueued_batches() const;
  void clear_max_enqueued_batches();
  static const int kMaxEnqueuedBatchesFieldNumber = 3;
  private:
  const ::google::protobuf::Int64Value& _internal_max_enqueued_batches() const;
  public:
  const ::google::protobuf::Int64Value& max_enqueued_batches() const;
  ::google::protobuf::Int64Value* release_max_enqueued_batches();
  ::google::protobuf::Int64Value* mutable_max_enqueued_batches();
  void set_allocated_max_enqueued_batches(::google::protobuf::Int64Value* max_enqueued_batches);

  // .google.protobuf.Int64Value num_batch_threads = 4;
  bool has_num_batch_threads() const;
  void clear_num_batch_threads();
  static const int kNumBatchThreadsFieldNumber = 4;
  private:
  const ::google::protobuf::Int64Value& _internal_num_batch_threads() const;
  public:
  const ::google::protobuf::Int64Value& num_batch_threads() const;
  ::google::protobuf::Int64Value* release_num_batch_threads();
  ::google::protobuf::Int64Value* mutable_num_batch_threads();
  void set_allocated_num_batch_threads(::google::protobuf::Int64Value* num_batch_threads);

  // .google.protobuf.StringValue thread_pool_name = 5;
  bool has_thread_pool_name() const;
  void clear_thread_pool_name();
  static const int kThreadPoolNameFieldNumber = 5;
  private:
  const ::google::protobuf::StringValue& _internal_thread_pool_name() const;
  public:
  const ::google::protobuf::StringValue& thread_pool_name() const;
  ::google::protobuf::StringValue* release_thread_pool_name();
  ::google::protobuf::StringValue* mutable_thread_pool_name();
  void set_allocated_thread_pool_name(::google::protobuf::StringValue* thread_pool_name);

  // bool pad_variable_length_inputs = 7;
  void clear_pad_variable_length_inputs();
  static const int kPadVariableLengthInputsFieldNumber = 7;
  bool pad_variable_length_inputs() const;
  void set_pad_variable_length_inputs(bool value);

  // @@protoc_insertion_point(class_scope:tensorflow.serving.BatchingParameters)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedField< ::google::protobuf::int64 > allowed_batch_sizes_;
  mutable int _allowed_batch_sizes_cached_byte_size_;
  ::google::protobuf::Int64Value* max_batch_size_;
  ::google::protobuf::Int64Value* batch_timeout_micros_;
  ::google::protobuf::Int64Value* max_enqueued_batches_;
  ::google::protobuf::Int64Value* num_batch_threads_;
  ::google::protobuf::StringValue* thread_pool_name_;
  bool pad_variable_length_inputs_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::TableStruct;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// SessionBundleConfig

// string session_target = 1;
inline void SessionBundleConfig::clear_session_target() {
  session_target_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& SessionBundleConfig::session_target() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.session_target)
  return session_target_.GetNoArena();
}
inline void SessionBundleConfig::set_session_target(const ::std::string& value) {
  
  session_target_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.SessionBundleConfig.session_target)
}
#if LANG_CXX11
inline void SessionBundleConfig::set_session_target(::std::string&& value) {
  
  session_target_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:tensorflow.serving.SessionBundleConfig.session_target)
}
#endif
inline void SessionBundleConfig::set_session_target(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  
  session_target_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.SessionBundleConfig.session_target)
}
inline void SessionBundleConfig::set_session_target(const char* value, size_t size) {
  
  session_target_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.SessionBundleConfig.session_target)
}
inline ::std::string* SessionBundleConfig::mutable_session_target() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.session_target)
  return session_target_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SessionBundleConfig::release_session_target() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionBundleConfig.session_target)
  
  return session_target_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SessionBundleConfig::set_allocated_session_target(::std::string* session_target) {
  if (session_target != NULL) {
    
  } else {
    
  }
  session_target_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), session_target);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionBundleConfig.session_target)
}

// .diplomacy.tensorflow.ConfigProto session_config = 2;
inline bool SessionBundleConfig::has_session_config() const {
  return this != internal_default_instance() && session_config_ != NULL;
}
inline const ::diplomacy::tensorflow::ConfigProto& SessionBundleConfig::_internal_session_config() const {
  return *session_config_;
}
inline const ::diplomacy::tensorflow::ConfigProto& SessionBundleConfig::session_config() const {
  const ::diplomacy::tensorflow::ConfigProto* p = session_config_;
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.session_config)
  return p != NULL ? *p : *reinterpret_cast<const ::diplomacy::tensorflow::ConfigProto*>(
      &::diplomacy::tensorflow::_ConfigProto_default_instance_);
}
inline ::diplomacy::tensorflow::ConfigProto* SessionBundleConfig::release_session_config() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionBundleConfig.session_config)
  
  ::diplomacy::tensorflow::ConfigProto* temp = session_config_;
  session_config_ = NULL;
  return temp;
}
inline ::diplomacy::tensorflow::ConfigProto* SessionBundleConfig::mutable_session_config() {
  
  if (session_config_ == NULL) {
    auto* p = CreateMaybeMessage<::diplomacy::tensorflow::ConfigProto>(GetArenaNoVirtual());
    session_config_ = p;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.session_config)
  return session_config_;
}
inline void SessionBundleConfig::set_allocated_session_config(::diplomacy::tensorflow::ConfigProto* session_config) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(session_config_);
  }
  if (session_config) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast<::google::protobuf::MessageLite*>(session_config)->GetArena();
    if (message_arena != submessage_arena) {
      session_config = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, session_config, submessage_arena);
    }
    
  } else {
    
  }
  session_config_ = session_config;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionBundleConfig.session_config)
}

// .tensorflow.serving.BatchingParameters batching_parameters = 3;
inline bool SessionBundleConfig::has_batching_parameters() const {
  return this != internal_default_instance() && batching_parameters_ != NULL;
}
inline void SessionBundleConfig::clear_batching_parameters() {
  if (GetArenaNoVirtual() == NULL && batching_parameters_ != NULL) {
    delete batching_parameters_;
  }
  batching_parameters_ = NULL;
}
inline const ::tensorflow::serving::BatchingParameters& SessionBundleConfig::_internal_batching_parameters() const {
  return *batching_parameters_;
}
inline const ::tensorflow::serving::BatchingParameters& SessionBundleConfig::batching_parameters() const {
  const ::tensorflow::serving::BatchingParameters* p = batching_parameters_;
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.batching_parameters)
  return p != NULL ? *p : *reinterpret_cast<const ::tensorflow::serving::BatchingParameters*>(
      &::tensorflow::serving::_BatchingParameters_default_instance_);
}
inline ::tensorflow::serving::BatchingParameters* SessionBundleConfig::release_batching_parameters() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionBundleConfig.batching_parameters)
  
  ::tensorflow::serving::BatchingParameters* temp = batching_parameters_;
  batching_parameters_ = NULL;
  return temp;
}
inline ::tensorflow::serving::BatchingParameters* SessionBundleConfig::mutable_batching_parameters() {
  
  if (batching_parameters_ == NULL) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::BatchingParameters>(GetArenaNoVirtual());
    batching_parameters_ = p;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.batching_parameters)
  return batching_parameters_;
}
inline void SessionBundleConfig::set_allocated_batching_parameters(::tensorflow::serving::BatchingParameters* batching_parameters) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete batching_parameters_;
  }
  if (batching_parameters) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      batching_parameters = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, batching_parameters, submessage_arena);
    }
    
  } else {
    
  }
  batching_parameters_ = batching_parameters;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionBundleConfig.batching_parameters)
}

// .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
inline bool SessionBundleConfig::has_session_run_load_threadpool_index() const {
  return this != internal_default_instance() && session_run_load_threadpool_index_ != NULL;
}
inline const ::google::protobuf::Int32Value& SessionBundleConfig::_internal_session_run_load_threadpool_index() const {
  return *session_run_load_threadpool_index_;
}
inline const ::google::protobuf::Int32Value& SessionBundleConfig::session_run_load_threadpool_index() const {
  const ::google::protobuf::Int32Value* p = session_run_load_threadpool_index_;
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.session_run_load_threadpool_index)
  return p != NULL ? *p : *reinterpret_cast<const ::google::protobuf::Int32Value*>(
      &::google::protobuf::_Int32Value_default_instance_);
}
inline ::google::protobuf::Int32Value* SessionBundleConfig::release_session_run_load_threadpool_index() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionBundleConfig.session_run_load_threadpool_index)
  
  ::google::protobuf::Int32Value* temp = session_run_load_threadpool_index_;
  session_run_load_threadpool_index_ = NULL;
  return temp;
}
inline ::google::protobuf::Int32Value* SessionBundleConfig::mutable_session_run_load_threadpool_index() {
  
  if (session_run_load_threadpool_index_ == NULL) {
    auto* p = CreateMaybeMessage<::google::protobuf::Int32Value>(GetArenaNoVirtual());
    session_run_load_threadpool_index_ = p;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.session_run_load_threadpool_index)
  return session_run_load_threadpool_index_;
}
inline void SessionBundleConfig::set_allocated_session_run_load_threadpool_index(::google::protobuf::Int32Value* session_run_load_threadpool_index) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(session_run_load_threadpool_index_);
  }
  if (session_run_load_threadpool_index) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast<::google::protobuf::MessageLite*>(session_run_load_threadpool_index)->GetArena();
    if (message_arena != submessage_arena) {
      session_run_load_threadpool_index = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, session_run_load_threadpool_index, submessage_arena);
    }
    
  } else {
    
  }
  session_run_load_threadpool_index_ = session_run_load_threadpool_index;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionBundleConfig.session_run_load_threadpool_index)
}

// uint64 experimental_transient_ram_bytes_during_load = 5;
inline void SessionBundleConfig::clear_experimental_transient_ram_bytes_during_load() {
  experimental_transient_ram_bytes_during_load_ = GOOGLE_ULONGLONG(0);
}
inline ::google::protobuf::uint64 SessionBundleConfig::experimental_transient_ram_bytes_during_load() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.experimental_transient_ram_bytes_during_load)
  return experimental_transient_ram_bytes_during_load_;
}
inline void SessionBundleConfig::set_experimental_transient_ram_bytes_during_load(::google::protobuf::uint64 value) {
  
  experimental_transient_ram_bytes_during_load_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.serving.SessionBundleConfig.experimental_transient_ram_bytes_during_load)
}

// repeated string saved_model_tags = 6;
inline int SessionBundleConfig::saved_model_tags_size() const {
  return saved_model_tags_.size();
}
inline void SessionBundleConfig::clear_saved_model_tags() {
  saved_model_tags_.Clear();
}
inline const ::std::string& SessionBundleConfig::saved_model_tags(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.saved_model_tags)
  return saved_model_tags_.Get(index);
}
inline ::std::string* SessionBundleConfig::mutable_saved_model_tags(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.saved_model_tags)
  return saved_model_tags_.Mutable(index);
}
inline void SessionBundleConfig::set_saved_model_tags(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.serving.SessionBundleConfig.saved_model_tags)
  saved_model_tags_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void SessionBundleConfig::set_saved_model_tags(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:tensorflow.serving.SessionBundleConfig.saved_model_tags)
  saved_model_tags_.Mutable(index)->assign(std::move(value));
}
#endif
inline void SessionBundleConfig::set_saved_model_tags(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  saved_model_tags_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.SessionBundleConfig.saved_model_tags)
}
inline void SessionBundleConfig::set_saved_model_tags(int index, const char* value, size_t size) {
  saved_model_tags_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.SessionBundleConfig.saved_model_tags)
}
inline ::std::string* SessionBundleConfig::add_saved_model_tags() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.serving.SessionBundleConfig.saved_model_tags)
  return saved_model_tags_.Add();
}
inline void SessionBundleConfig::add_saved_model_tags(const ::std::string& value) {
  saved_model_tags_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.serving.SessionBundleConfig.saved_model_tags)
}
#if LANG_CXX11
inline void SessionBundleConfig::add_saved_model_tags(::std::string&& value) {
  saved_model_tags_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:tensorflow.serving.SessionBundleConfig.saved_model_tags)
}
#endif
inline void SessionBundleConfig::add_saved_model_tags(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  saved_model_tags_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.serving.SessionBundleConfig.saved_model_tags)
}
inline void SessionBundleConfig::add_saved_model_tags(const char* value, size_t size) {
  saved_model_tags_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.serving.SessionBundleConfig.saved_model_tags)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
SessionBundleConfig::saved_model_tags() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.SessionBundleConfig.saved_model_tags)
  return saved_model_tags_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
SessionBundleConfig::mutable_saved_model_tags() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.SessionBundleConfig.saved_model_tags)
  return &saved_model_tags_;
}

// repeated .diplomacy.tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
inline int SessionBundleConfig::experimental_fixed_input_tensors_size() const {
  return experimental_fixed_input_tensors_.size();
}
inline ::diplomacy::tensorflow::NamedTensorProto* SessionBundleConfig::mutable_experimental_fixed_input_tensors(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return experimental_fixed_input_tensors_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::diplomacy::tensorflow::NamedTensorProto >*
SessionBundleConfig::mutable_experimental_fixed_input_tensors() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return &experimental_fixed_input_tensors_;
}
inline const ::diplomacy::tensorflow::NamedTensorProto& SessionBundleConfig::experimental_fixed_input_tensors(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return experimental_fixed_input_tensors_.Get(index);
}
inline ::diplomacy::tensorflow::NamedTensorProto* SessionBundleConfig::add_experimental_fixed_input_tensors() {
  // @@protoc_insertion_point(field_add:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return experimental_fixed_input_tensors_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::diplomacy::tensorflow::NamedTensorProto >&
SessionBundleConfig::experimental_fixed_input_tensors() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return experimental_fixed_input_tensors_;
}

// bool enable_model_warmup = 779;
inline void SessionBundleConfig::clear_enable_model_warmup() {
  enable_model_warmup_ = false;
}
inline bool SessionBundleConfig::enable_model_warmup() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.enable_model_warmup)
  return enable_model_warmup_;
}
inline void SessionBundleConfig::set_enable_model_warmup(bool value) {
  
  enable_model_warmup_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.serving.SessionBundleConfig.enable_model_warmup)
}

// -------------------------------------------------------------------

// BatchingParameters

// .google.protobuf.Int64Value max_batch_size = 1;
inline bool BatchingParameters::has_max_batch_size() const {
  return this != internal_default_instance() && max_batch_size_ != NULL;
}
inline const ::google::protobuf::Int64Value& BatchingParameters::_internal_max_batch_size() const {
  return *max_batch_size_;
}
inline const ::google::protobuf::Int64Value& BatchingParameters::max_batch_size() const {
  const ::google::protobuf::Int64Value* p = max_batch_size_;
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.max_batch_size)
  return p != NULL ? *p : *reinterpret_cast<const ::google::protobuf::Int64Value*>(
      &::google::protobuf::_Int64Value_default_instance_);
}
inline ::google::protobuf::Int64Value* BatchingParameters::release_max_batch_size() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.max_batch_size)
  
  ::google::protobuf::Int64Value* temp = max_batch_size_;
  max_batch_size_ = NULL;
  return temp;
}
inline ::google::protobuf::Int64Value* BatchingParameters::mutable_max_batch_size() {
  
  if (max_batch_size_ == NULL) {
    auto* p = CreateMaybeMessage<::google::protobuf::Int64Value>(GetArenaNoVirtual());
    max_batch_size_ = p;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.max_batch_size)
  return max_batch_size_;
}
inline void BatchingParameters::set_allocated_max_batch_size(::google::protobuf::Int64Value* max_batch_size) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(max_batch_size_);
  }
  if (max_batch_size) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast<::google::protobuf::MessageLite*>(max_batch_size)->GetArena();
    if (message_arena != submessage_arena) {
      max_batch_size = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, max_batch_size, submessage_arena);
    }
    
  } else {
    
  }
  max_batch_size_ = max_batch_size;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.max_batch_size)
}

// .google.protobuf.Int64Value batch_timeout_micros = 2;
inline bool BatchingParameters::has_batch_timeout_micros() const {
  return this != internal_default_instance() && batch_timeout_micros_ != NULL;
}
inline const ::google::protobuf::Int64Value& BatchingParameters::_internal_batch_timeout_micros() const {
  return *batch_timeout_micros_;
}
inline const ::google::protobuf::Int64Value& BatchingParameters::batch_timeout_micros() const {
  const ::google::protobuf::Int64Value* p = batch_timeout_micros_;
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.batch_timeout_micros)
  return p != NULL ? *p : *reinterpret_cast<const ::google::protobuf::Int64Value*>(
      &::google::protobuf::_Int64Value_default_instance_);
}
inline ::google::protobuf::Int64Value* BatchingParameters::release_batch_timeout_micros() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.batch_timeout_micros)
  
  ::google::protobuf::Int64Value* temp = batch_timeout_micros_;
  batch_timeout_micros_ = NULL;
  return temp;
}
inline ::google::protobuf::Int64Value* BatchingParameters::mutable_batch_timeout_micros() {
  
  if (batch_timeout_micros_ == NULL) {
    auto* p = CreateMaybeMessage<::google::protobuf::Int64Value>(GetArenaNoVirtual());
    batch_timeout_micros_ = p;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.batch_timeout_micros)
  return batch_timeout_micros_;
}
inline void BatchingParameters::set_allocated_batch_timeout_micros(::google::protobuf::Int64Value* batch_timeout_micros) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(batch_timeout_micros_);
  }
  if (batch_timeout_micros) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast<::google::protobuf::MessageLite*>(batch_timeout_micros)->GetArena();
    if (message_arena != submessage_arena) {
      batch_timeout_micros = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, batch_timeout_micros, submessage_arena);
    }
    
  } else {
    
  }
  batch_timeout_micros_ = batch_timeout_micros;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.batch_timeout_micros)
}

// .google.protobuf.Int64Value max_enqueued_batches = 3;
inline bool BatchingParameters::has_max_enqueued_batches() const {
  return this != internal_default_instance() && max_enqueued_batches_ != NULL;
}
inline const ::google::protobuf::Int64Value& BatchingParameters::_internal_max_enqueued_batches() const {
  return *max_enqueued_batches_;
}
inline const ::google::protobuf::Int64Value& BatchingParameters::max_enqueued_batches() const {
  const ::google::protobuf::Int64Value* p = max_enqueued_batches_;
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.max_enqueued_batches)
  return p != NULL ? *p : *reinterpret_cast<const ::google::protobuf::Int64Value*>(
      &::google::protobuf::_Int64Value_default_instance_);
}
inline ::google::protobuf::Int64Value* BatchingParameters::release_max_enqueued_batches() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.max_enqueued_batches)
  
  ::google::protobuf::Int64Value* temp = max_enqueued_batches_;
  max_enqueued_batches_ = NULL;
  return temp;
}
inline ::google::protobuf::Int64Value* BatchingParameters::mutable_max_enqueued_batches() {
  
  if (max_enqueued_batches_ == NULL) {
    auto* p = CreateMaybeMessage<::google::protobuf::Int64Value>(GetArenaNoVirtual());
    max_enqueued_batches_ = p;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.max_enqueued_batches)
  return max_enqueued_batches_;
}
inline void BatchingParameters::set_allocated_max_enqueued_batches(::google::protobuf::Int64Value* max_enqueued_batches) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(max_enqueued_batches_);
  }
  if (max_enqueued_batches) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast<::google::protobuf::MessageLite*>(max_enqueued_batches)->GetArena();
    if (message_arena != submessage_arena) {
      max_enqueued_batches = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, max_enqueued_batches, submessage_arena);
    }
    
  } else {
    
  }
  max_enqueued_batches_ = max_enqueued_batches;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.max_enqueued_batches)
}

// .google.protobuf.Int64Value num_batch_threads = 4;
inline bool BatchingParameters::has_num_batch_threads() const {
  return this != internal_default_instance() && num_batch_threads_ != NULL;
}
inline const ::google::protobuf::Int64Value& BatchingParameters::_internal_num_batch_threads() const {
  return *num_batch_threads_;
}
inline const ::google::protobuf::Int64Value& BatchingParameters::num_batch_threads() const {
  const ::google::protobuf::Int64Value* p = num_batch_threads_;
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.num_batch_threads)
  return p != NULL ? *p : *reinterpret_cast<const ::google::protobuf::Int64Value*>(
      &::google::protobuf::_Int64Value_default_instance_);
}
inline ::google::protobuf::Int64Value* BatchingParameters::release_num_batch_threads() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.num_batch_threads)
  
  ::google::protobuf::Int64Value* temp = num_batch_threads_;
  num_batch_threads_ = NULL;
  return temp;
}
inline ::google::protobuf::Int64Value* BatchingParameters::mutable_num_batch_threads() {
  
  if (num_batch_threads_ == NULL) {
    auto* p = CreateMaybeMessage<::google::protobuf::Int64Value>(GetArenaNoVirtual());
    num_batch_threads_ = p;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.num_batch_threads)
  return num_batch_threads_;
}
inline void BatchingParameters::set_allocated_num_batch_threads(::google::protobuf::Int64Value* num_batch_threads) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(num_batch_threads_);
  }
  if (num_batch_threads) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast<::google::protobuf::MessageLite*>(num_batch_threads)->GetArena();
    if (message_arena != submessage_arena) {
      num_batch_threads = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, num_batch_threads, submessage_arena);
    }
    
  } else {
    
  }
  num_batch_threads_ = num_batch_threads;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.num_batch_threads)
}

// .google.protobuf.StringValue thread_pool_name = 5;
inline bool BatchingParameters::has_thread_pool_name() const {
  return this != internal_default_instance() && thread_pool_name_ != NULL;
}
inline const ::google::protobuf::StringValue& BatchingParameters::_internal_thread_pool_name() const {
  return *thread_pool_name_;
}
inline const ::google::protobuf::StringValue& BatchingParameters::thread_pool_name() const {
  const ::google::protobuf::StringValue* p = thread_pool_name_;
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.thread_pool_name)
  return p != NULL ? *p : *reinterpret_cast<const ::google::protobuf::StringValue*>(
      &::google::protobuf::_StringValue_default_instance_);
}
inline ::google::protobuf::StringValue* BatchingParameters::release_thread_pool_name() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.thread_pool_name)
  
  ::google::protobuf::StringValue* temp = thread_pool_name_;
  thread_pool_name_ = NULL;
  return temp;
}
inline ::google::protobuf::StringValue* BatchingParameters::mutable_thread_pool_name() {
  
  if (thread_pool_name_ == NULL) {
    auto* p = CreateMaybeMessage<::google::protobuf::StringValue>(GetArenaNoVirtual());
    thread_pool_name_ = p;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.thread_pool_name)
  return thread_pool_name_;
}
inline void BatchingParameters::set_allocated_thread_pool_name(::google::protobuf::StringValue* thread_pool_name) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(thread_pool_name_);
  }
  if (thread_pool_name) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast<::google::protobuf::MessageLite*>(thread_pool_name)->GetArena();
    if (message_arena != submessage_arena) {
      thread_pool_name = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, thread_pool_name, submessage_arena);
    }
    
  } else {
    
  }
  thread_pool_name_ = thread_pool_name;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.thread_pool_name)
}

// repeated int64 allowed_batch_sizes = 6;
inline int BatchingParameters::allowed_batch_sizes_size() const {
  return allowed_batch_sizes_.size();
}
inline void BatchingParameters::clear_allowed_batch_sizes() {
  allowed_batch_sizes_.Clear();
}
inline ::google::protobuf::int64 BatchingParameters::allowed_batch_sizes(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
  return allowed_batch_sizes_.Get(index);
}
inline void BatchingParameters::set_allowed_batch_sizes(int index, ::google::protobuf::int64 value) {
  allowed_batch_sizes_.Set(index, value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
}
inline void BatchingParameters::add_allowed_batch_sizes(::google::protobuf::int64 value) {
  allowed_batch_sizes_.Add(value);
  // @@protoc_insertion_point(field_add:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
}
inline const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
BatchingParameters::allowed_batch_sizes() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
  return allowed_batch_sizes_;
}
inline ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
BatchingParameters::mutable_allowed_batch_sizes() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
  return &allowed_batch_sizes_;
}

// bool pad_variable_length_inputs = 7;
inline void BatchingParameters::clear_pad_variable_length_inputs() {
  pad_variable_length_inputs_ = false;
}
inline bool BatchingParameters::pad_variable_length_inputs() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.pad_variable_length_inputs)
  return pad_variable_length_inputs_;
}
inline void BatchingParameters::set_pad_variable_length_inputs(bool value) {
  
  pad_variable_length_inputs_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.serving.BatchingParameters.pad_variable_length_inputs)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_INCLUDED_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto
