// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: diplomacy_tensorflow/compiler/xla/service/gpu/backend_configs.proto

#include "diplomacy_tensorflow/compiler/xla/service/gpu/backend_configs.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// This is a temporary google only hack
#ifdef GOOGLE_PROTOBUF_ENFORCE_UNIQUENESS
#include "third_party/protobuf/version.h"
#endif
// @@protoc_insertion_point(includes)

namespace xla {
namespace gpu {
class CudnnConvBackendConfigDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<CudnnConvBackendConfig>
      _instance;
} _CudnnConvBackendConfig_default_instance_;
}  // namespace gpu
}  // namespace xla
namespace protobuf_diplomacy_5ftensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto {
static void InitDefaultsCudnnConvBackendConfig() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::xla::gpu::_CudnnConvBackendConfig_default_instance_;
    new (ptr) ::xla::gpu::CudnnConvBackendConfig();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::xla::gpu::CudnnConvBackendConfig::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<0> scc_info_CudnnConvBackendConfig =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 0, InitDefaultsCudnnConvBackendConfig}, {}};

void InitDefaults() {
  ::google::protobuf::internal::InitSCC(&scc_info_CudnnConvBackendConfig.base);
}

::google::protobuf::Metadata file_level_metadata[1];

const ::google::protobuf::uint32 TableStruct::offsets[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::xla::gpu::CudnnConvBackendConfig, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::xla::gpu::CudnnConvBackendConfig, algorithm_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::xla::gpu::CudnnConvBackendConfig, tensor_ops_enabled_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::xla::gpu::CudnnConvBackendConfig, conv_result_scale_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::xla::gpu::CudnnConvBackendConfig, activation_mode_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::xla::gpu::CudnnConvBackendConfig, side_input_scale_),
};
static const ::google::protobuf::internal::MigrationSchema schemas[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, sizeof(::xla::gpu::CudnnConvBackendConfig)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&::xla::gpu::_CudnnConvBackendConfig_default_instance_),
};

void protobuf_AssignDescriptors() {
  AddDescriptors();
  AssignDescriptors(
      "diplomacy_tensorflow/compiler/xla/service/gpu/backend_configs.proto", schemas, file_default_instances, TableStruct::offsets,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_PROTOBUF_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 1);
}

void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
      "\nCdiplomacy_tensorflow/compiler/xla/serv"
      "ice/gpu/backend_configs.proto\022\007xla.gpu\"\225"
      "\001\n\026CudnnConvBackendConfig\022\021\n\talgorithm\030\001"
      " \001(\003\022\032\n\022tensor_ops_enabled\030\002 \001(\010\022\031\n\021conv"
      "_result_scale\030\004 \001(\001\022\027\n\017activation_mode\030\003"
      " \001(\003\022\030\n\020side_input_scale\030\005 \001(\001b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 238);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "diplomacy_tensorflow/compiler/xla/service/gpu/backend_configs.proto", &protobuf_RegisterTypes);
}

void AddDescriptors() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at dynamic initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;
}  // namespace protobuf_diplomacy_5ftensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto
namespace xla {
namespace gpu {

// ===================================================================

void CudnnConvBackendConfig::InitAsDefaultInstance() {
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CudnnConvBackendConfig::kAlgorithmFieldNumber;
const int CudnnConvBackendConfig::kTensorOpsEnabledFieldNumber;
const int CudnnConvBackendConfig::kConvResultScaleFieldNumber;
const int CudnnConvBackendConfig::kActivationModeFieldNumber;
const int CudnnConvBackendConfig::kSideInputScaleFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CudnnConvBackendConfig::CudnnConvBackendConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_diplomacy_5ftensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto::scc_info_CudnnConvBackendConfig.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:xla.gpu.CudnnConvBackendConfig)
}
CudnnConvBackendConfig::CudnnConvBackendConfig(const CudnnConvBackendConfig& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::memcpy(&algorithm_, &from.algorithm_,
    static_cast<size_t>(reinterpret_cast<char*>(&tensor_ops_enabled_) -
    reinterpret_cast<char*>(&algorithm_)) + sizeof(tensor_ops_enabled_));
  // @@protoc_insertion_point(copy_constructor:xla.gpu.CudnnConvBackendConfig)
}

void CudnnConvBackendConfig::SharedCtor() {
  ::memset(&algorithm_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&tensor_ops_enabled_) -
      reinterpret_cast<char*>(&algorithm_)) + sizeof(tensor_ops_enabled_));
}

CudnnConvBackendConfig::~CudnnConvBackendConfig() {
  // @@protoc_insertion_point(destructor:xla.gpu.CudnnConvBackendConfig)
  SharedDtor();
}

void CudnnConvBackendConfig::SharedDtor() {
}

void CudnnConvBackendConfig::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* CudnnConvBackendConfig::descriptor() {
  ::protobuf_diplomacy_5ftensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_diplomacy_5ftensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const CudnnConvBackendConfig& CudnnConvBackendConfig::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_diplomacy_5ftensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto::scc_info_CudnnConvBackendConfig.base);
  return *internal_default_instance();
}


void CudnnConvBackendConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:xla.gpu.CudnnConvBackendConfig)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&algorithm_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&tensor_ops_enabled_) -
      reinterpret_cast<char*>(&algorithm_)) + sizeof(tensor_ops_enabled_));
  _internal_metadata_.Clear();
}

bool CudnnConvBackendConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:xla.gpu.CudnnConvBackendConfig)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // int64 algorithm = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(8u /* 8 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &algorithm_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool tensor_ops_enabled = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u /* 16 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &tensor_ops_enabled_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // int64 activation_mode = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(24u /* 24 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &activation_mode_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // double conv_result_scale = 4;
      case 4: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(33u /* 33 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &conv_result_scale_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // double side_input_scale = 5;
      case 5: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(41u /* 41 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &side_input_scale_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:xla.gpu.CudnnConvBackendConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:xla.gpu.CudnnConvBackendConfig)
  return false;
#undef DO_
}

void CudnnConvBackendConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:xla.gpu.CudnnConvBackendConfig)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 algorithm = 1;
  if (this->algorithm() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->algorithm(), output);
  }

  // bool tensor_ops_enabled = 2;
  if (this->tensor_ops_enabled() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->tensor_ops_enabled(), output);
  }

  // int64 activation_mode = 3;
  if (this->activation_mode() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(3, this->activation_mode(), output);
  }

  // double conv_result_scale = 4;
  if (this->conv_result_scale() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(4, this->conv_result_scale(), output);
  }

  // double side_input_scale = 5;
  if (this->side_input_scale() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(5, this->side_input_scale(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:xla.gpu.CudnnConvBackendConfig)
}

::google::protobuf::uint8* CudnnConvBackendConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:xla.gpu.CudnnConvBackendConfig)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 algorithm = 1;
  if (this->algorithm() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->algorithm(), target);
  }

  // bool tensor_ops_enabled = 2;
  if (this->tensor_ops_enabled() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->tensor_ops_enabled(), target);
  }

  // int64 activation_mode = 3;
  if (this->activation_mode() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(3, this->activation_mode(), target);
  }

  // double conv_result_scale = 4;
  if (this->conv_result_scale() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(4, this->conv_result_scale(), target);
  }

  // double side_input_scale = 5;
  if (this->side_input_scale() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(5, this->side_input_scale(), target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:xla.gpu.CudnnConvBackendConfig)
  return target;
}

size_t CudnnConvBackendConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:xla.gpu.CudnnConvBackendConfig)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // int64 algorithm = 1;
  if (this->algorithm() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->algorithm());
  }

  // int64 activation_mode = 3;
  if (this->activation_mode() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->activation_mode());
  }

  // double conv_result_scale = 4;
  if (this->conv_result_scale() != 0) {
    total_size += 1 + 8;
  }

  // double side_input_scale = 5;
  if (this->side_input_scale() != 0) {
    total_size += 1 + 8;
  }

  // bool tensor_ops_enabled = 2;
  if (this->tensor_ops_enabled() != 0) {
    total_size += 1 + 1;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void CudnnConvBackendConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:xla.gpu.CudnnConvBackendConfig)
  GOOGLE_DCHECK_NE(&from, this);
  const CudnnConvBackendConfig* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const CudnnConvBackendConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:xla.gpu.CudnnConvBackendConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:xla.gpu.CudnnConvBackendConfig)
    MergeFrom(*source);
  }
}

void CudnnConvBackendConfig::MergeFrom(const CudnnConvBackendConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:xla.gpu.CudnnConvBackendConfig)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.algorithm() != 0) {
    set_algorithm(from.algorithm());
  }
  if (from.activation_mode() != 0) {
    set_activation_mode(from.activation_mode());
  }
  if (from.conv_result_scale() != 0) {
    set_conv_result_scale(from.conv_result_scale());
  }
  if (from.side_input_scale() != 0) {
    set_side_input_scale(from.side_input_scale());
  }
  if (from.tensor_ops_enabled() != 0) {
    set_tensor_ops_enabled(from.tensor_ops_enabled());
  }
}

void CudnnConvBackendConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:xla.gpu.CudnnConvBackendConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CudnnConvBackendConfig::CopyFrom(const CudnnConvBackendConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:xla.gpu.CudnnConvBackendConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CudnnConvBackendConfig::IsInitialized() const {
  return true;
}

void CudnnConvBackendConfig::Swap(CudnnConvBackendConfig* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CudnnConvBackendConfig::InternalSwap(CudnnConvBackendConfig* other) {
  using std::swap;
  swap(algorithm_, other->algorithm_);
  swap(activation_mode_, other->activation_mode_);
  swap(conv_result_scale_, other->conv_result_scale_);
  swap(side_input_scale_, other->side_input_scale_);
  swap(tensor_ops_enabled_, other->tensor_ops_enabled_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata CudnnConvBackendConfig::GetMetadata() const {
  protobuf_diplomacy_5ftensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_diplomacy_5ftensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto::file_level_metadata[kIndexInFileMessages];
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace gpu
}  // namespace xla
namespace google {
namespace protobuf {
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::xla::gpu::CudnnConvBackendConfig* Arena::CreateMaybeMessage< ::xla::gpu::CudnnConvBackendConfig >(Arena* arena) {
  return Arena::CreateInternal< ::xla::gpu::CudnnConvBackendConfig >(arena);
}
}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)
